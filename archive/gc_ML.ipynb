{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # used for loading images\n",
    "import numpy as np\n",
    "import os # used for navigating to image path\n",
    "import imageio # used for writing images\n",
    "import matplotlib.pyplot as plt\n",
    "DIR = \"resources/brick_siding_combo_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE IMG CLASS TO NUMPY\n",
    "    #10_34.jpg\n",
    "    #10_34.jpg---->10-----> [1,0]\n",
    "    #20_550.jpg---->20-----> [0,1]\n",
    "def label_img(name):\n",
    "    \n",
    "  word_label = name.split('_')[0]\n",
    "  if word_label == '10' : return np.array([1, 0])\n",
    "  elif word_label == '20' : return np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE SIZE\n",
    "def get_size_statistics(DIR):\n",
    "  heights = []\n",
    "  widths = []\n",
    "  for img in os.listdir(DIR): \n",
    "    path = os.path.join(DIR, img)\n",
    "    data = np.array(Image.open(path)) #PIL Image library\n",
    "    heights.append(data.shape[0])\n",
    "    widths.append(data.shape[1])\n",
    "  avg_height = sum(heights) / len(heights)\n",
    "  avg_width = sum(widths) / len(widths)\n",
    "  print(\"Average Height: \" + str(avg_height))\n",
    "  print(\"Max Height: \" + str(max(heights)))\n",
    "  print(\"Min Height: \" + str(min(heights)))\n",
    "  print('\\n')\n",
    "  print(\"Average Width: \" + str(avg_width))\n",
    "  print(\"Max Width: \" + str(max(widths)))\n",
    "  print(\"Min Width: \" + str(min(widths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height: 600.0\n",
      "Max Height: 600\n",
      "Min Height: 600\n",
      "\n",
      "\n",
      "Average Width: 600.0\n",
      "Max Width: 600\n",
      "Min Width: 600\n"
     ]
    }
   ],
   "source": [
    "get_size_statistics(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "IMG_SIZE = 300\n",
    "\n",
    "def load_training_data():\n",
    "  train_data = []\n",
    "  for img in os.listdir(DIR):\n",
    "    label = label_img(img)\n",
    "    path = os.path.join(DIR, img)\n",
    "    img = Image.open(path)\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "    train_data.append([np.array(img), label])\n",
    "    # Basic Data Augmentation - Horizontal Flipping\n",
    "    flip_img = Image.open(path)\n",
    "    flip_img = flip_img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "    flip_img = np.array(flip_img)\n",
    "    flip_img = np.fliplr(flip_img)\n",
    "    train_data.append([flip_img, label])\n",
    "  shuffle(train_data)\n",
    "  return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_training_data()\n",
    "plt.imshow(train_data[43][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainImages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7350d3825317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainImages' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(trainImages, trainLabels, batch_size = 50, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
