{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "# from PIL import ImageFile\n",
    "from PIL import Image\n",
    "from PIL.Image import core as _imaging\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 image categories.\n",
      "Three categories:\n",
      "['brick_10/', 'siding_20/', 'unknown_00/']\n"
     ]
    }
   ],
   "source": [
    "image_names = [item.replace('resources/data_for_training_01/', '') for item in sorted(glob(\"resources/data_for_training_01/*/\"))]\n",
    "number_of_image_categories = len(image_names)\n",
    "print('%d image categories.' % number_of_image_categories)\n",
    "print('Three categories:')\n",
    "print(image_names[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 images.\n",
      "\n",
      "540 training images.\n",
      "180 validation images.\n",
      "181 test images.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    image_files = np.array(data['filenames'])\n",
    "    image_targets = np_utils.to_categorical(np.array(data['target']), number_of_image_categories)\n",
    "    return image_files, image_targets\n",
    "\n",
    "\n",
    "image_files, image_targets = load_dataset('resources/data_for_training_01/')\n",
    "\n",
    "trains_validate_files, test_files, trains_validate_targets, test_targets = \\\n",
    "    train_test_split(image_files, image_targets, test_size=0.2, random_state=42)\n",
    "\n",
    "train_files, valid_files, train_targets, valid_targets = \\\n",
    "    train_test_split(trains_validate_files, trains_validate_targets, test_size=0.25, random_state=42)\n",
    "\n",
    "image_names = [item[20:-1] for item in sorted(glob(\"resources/data_for_training_01/*/\"))]\n",
    "\n",
    "print('%s images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('%d training images.' % len(train_files))\n",
    "print('%d validation images.' % len(valid_files))\n",
    "print('%d test images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function for preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(100, 100))\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/540 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4/540 [00:00<00:14, 37.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14/540 [00:00<00:11, 46.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 26/540 [00:00<00:09, 56.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 38/540 [00:00<00:07, 66.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 50/540 [00:00<00:06, 76.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 61/540 [00:00<00:05, 82.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 71/540 [00:00<00:05, 86.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 82/540 [00:00<00:05, 91.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 94/540 [00:00<00:04, 96.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 105/540 [00:01<00:04, 99.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 117/540 [00:01<00:04, 104.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 130/540 [00:01<00:03, 109.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 143/540 [00:01<00:03, 112.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 156/540 [00:01<00:03, 116.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 168/540 [00:01<00:03, 116.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 180/540 [00:01<00:03, 116.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 192/540 [00:01<00:02, 116.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 204/540 [00:01<00:02, 117.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 216/540 [00:01<00:02, 115.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 228/540 [00:02<00:02, 116.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 240/540 [00:02<00:02, 115.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 252/540 [00:02<00:02, 114.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 264/540 [00:02<00:02, 110.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 276/540 [00:02<00:02, 112.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 288/540 [00:02<00:02, 112.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 300/540 [00:02<00:02, 113.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 312/540 [00:02<00:02, 111.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 324/540 [00:02<00:01, 113.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 336/540 [00:03<00:01, 115.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 349/540 [00:03<00:01, 116.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 362/540 [00:03<00:01, 120.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 375/540 [00:03<00:01, 122.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 388/540 [00:03<00:01, 122.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 401/540 [00:03<00:01, 121.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 414/540 [00:03<00:01, 122.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 427/540 [00:03<00:00, 121.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 440/540 [00:03<00:00, 120.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 453/540 [00:04<00:00, 119.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 465/540 [00:04<00:00, 119.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 478/540 [00:04<00:00, 120.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 491/540 [00:04<00:00, 121.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 504/540 [00:04<00:00, 119.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 516/540 [00:04<00:00, 119.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 540/540 [00:04<00:00, 114.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 12/180 [00:00<00:01, 117.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 25/180 [00:00<00:01, 118.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 38/180 [00:00<00:01, 120.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 51/180 [00:00<00:01, 119.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7fb324dca590>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0423aab06fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pre-process the data for Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvalid_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f70fb0f162d2>\u001b[0m in \u001b[0;36mpaths_to_tensor\u001b[0;34m(img_paths)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f70fb0f162d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpaths_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlist_of_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f70fb0f162d2>\u001b[0m in \u001b[0;36mpath_to_tensor\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpath_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[1;32m    300\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 301\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     )\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7fb324dca590>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|██▊       | 51/180 [00:11<00:01, 119.86it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<_io.BytesIO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
