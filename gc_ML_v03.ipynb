{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This ML script would not have been possible without inspiration from, github user ***'wiamsuri'*** and their project ***'cnn-image-classifier-keras'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "# from PIL import ImageFile\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import json\n",
    "import zipfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = 'resources/data_for_training_06.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('resources')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 image categories.\n",
      "Three categories:\n",
      "['.DS_Store', 'brick_10', 'siding_20']\n"
     ]
    }
   ],
   "source": [
    "image_names = sorted(os.listdir('resources/data_for_training_06'))\n",
    "number_of_image_categories = len(image_names)\n",
    "print('%d image categories.' % number_of_image_categories)\n",
    "print('Three categories:')\n",
    "print(image_names[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'brick_10', 'siding_20', 'unknown_00']\n",
      "4105 images.\n",
      "\n",
      "['resources/data_for_training_06/brick_10\\\\10_13306.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13167.jpeg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_14522.jpg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_11301.jpg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_9303.jpg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_11887.jpg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13271.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13018.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_9747.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12591.jpeg']\n",
      "2463 training images.\n",
      "['resources/data_for_training_06/brick_10\\\\10_13163.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12536.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13398.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_9143.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_9098.jpeg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_11353.jpg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_14538.jpg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_14502.jpg'\n",
      " 'resources/data_for_training_06/unknown_00\\\\00_209.jpg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12584.jpeg']\n",
      "821 validation images.\n",
      "['resources/data_for_training_06/brick_10\\\\10_463.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_305.jpeg'\n",
      " 'resources/data_for_training_06/unknown_00\\\\00_443.jpg'\n",
      " 'resources/data_for_training_06/unknown_00\\\\00_9268.jpg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12870.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13379.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12682.jpeg'\n",
      " 'resources/data_for_training_06/siding_20\\\\20_11584.jpg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_13717.jpeg'\n",
      " 'resources/data_for_training_06/brick_10\\\\10_12646.jpeg']\n",
      "821 test images.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    image_files = np.array(data['filenames'])\n",
    "    image_targets = np_utils.to_categorical(np.array(data['target']), number_of_image_categories)\n",
    "    return image_files, image_targets\n",
    "\n",
    "image_files, image_targets = load_dataset('resources/data_for_training_06/')\n",
    "\n",
    "trains_validate_files, test_files, trains_validate_targets, test_targets = \\\n",
    "    train_test_split(image_files, image_targets, test_size=0.2, random_state=42)\n",
    "\n",
    "train_files, valid_files, train_targets, valid_targets = \\\n",
    "    train_test_split(trains_validate_files, trains_validate_targets, test_size=0.25, random_state=42)\n",
    "\n",
    "print(image_names)\n",
    "\n",
    "print('%s images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print(train_files[:10])\n",
    "print('%d training images.' % len(train_files))\n",
    "print(valid_files[:10])\n",
    "print('%d validation images.' % len(valid_files))\n",
    "print(test_files[:10])\n",
    "print('%d test images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function for preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, grayscale=False, color_mode=\"rgb\", target_size=(400, 400), interpolation=\"nearest\")\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2463/2463 [00:18<00:00, 132.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 821/821 [00:06<00:00, 118.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 821/821 [00:06<00:00, 133.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 400, 400, 4)       52        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 200, 200, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 8)       136       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 8)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 100, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 12)      396       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 12)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 16)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2560256   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,562,395\n",
      "Trainable params: 2,562,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=2, padding='same',\n",
    "                 activation='relu', input_shape=(400, 400, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(filters=12, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('model_characteristics.txt', 'w')\n",
    "sys.stdout = f\n",
    "print(model.summary())\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020111520'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().time\n",
    "datetime.now().month\n",
    "datetime.now().day\n",
    "datetime.now().hour\n",
    "datetime.now().second\n",
    "\n",
    "current_time = str(datetime.now().year) + str(datetime.now().month) + str(datetime.now().day) + str(datetime.now().hour)\n",
    "current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with training and validating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 4) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-4e556bbd5e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                verbose=1, save_best_only=True)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n\u001b[0m\u001b[0;32m      7\u001b[0m           epochs=epochs, batch_size=64, callbacks=[checkpointer], verbose=1)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\david\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 4) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=f'saved_models/{current_time}image_classifier.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=64, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('saved_models/final_model.hdf5')\n",
    "\n",
    "# #Save the model\n",
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"saved_models/final_model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"final_model.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"brick images:\")\n",
    "for image in os.listdir('test_imgs'):\n",
    "    img = plt.imread('test_imgs' + '/' + image)\n",
    "    resized_image = resize(img, (400,400,3))\n",
    "    predictions = model.predict(np.array([resized_image]))\n",
    "    if image.split(\"_\")[0] == \"brick\":\n",
    "        print(image, predictions)\n",
    "print()\n",
    "print(\"siding images:\")\n",
    "for image in os.listdir('test_imgs'):\n",
    "    img = plt.imread('test_imgs' + '/' + image)\n",
    "    resized_image = resize(img, (400,400,3))\n",
    "    predictions = model.predict(np.array([resized_image]))\n",
    "    if image.split(\"_\")[0] == \"siding\":\n",
    "        print(image, predictions)\n",
    "\n",
    "print()\n",
    "print(\"unknown images:\")\n",
    "for image in os.listdir('test_imgs'):\n",
    "    img = plt.imread('test_imgs' + '/' + image)\n",
    "    resized_image = resize(img, (400,400,3))\n",
    "    predictions = model.predict(np.array([resized_image]))\n",
    "    if image.split(\"_\")[0] == \"unknown\":\n",
    "        print(image, predictions)\n",
    "\n",
    "#['brick_10/', 'siding_20/', 'unknown_00/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_guess(path, house_type): #brick, siding, or unknown\n",
    "    classification = ['brick', 'siding', 'unknown']\n",
    "    print()\n",
    "    print(f'Predictions for {house_type}: Percentage accuracy of model versus a human')\n",
    "    print()\n",
    "    index = classification.index(house_type)\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    total_images = 0\n",
    "    for image in os.listdir(path):  \n",
    "        if image.split(\"_\")[0] == house_type:\n",
    "            total_images += 1\n",
    "            img = plt.imread('test_imgs' + '/' + image)\n",
    "            resized_image = resize(img, (400,400,3))\n",
    "            predictions = model.predict(np.array([resized_image]))\n",
    "            if predictions[0][index] == predictions[0].max():\n",
    "                print(f\"\\n{image}: Correct\")\n",
    "                correct += 1\n",
    "            else:\n",
    "                print(f\"\\n{image}: Wrong\")\n",
    "                wrong += 1\n",
    "            for i, prediction in enumerate(predictions[0]):\n",
    "                print('\\t',classification[i], round(100*prediction,0),'%')\n",
    "    print()\n",
    "    print('Stats:')\n",
    "    print('\\tTotal images:', total_images)\n",
    "    print('\\tAccuracy:', round(100*correct/(correct+wrong),0),'%')\n",
    "    print('\\tCorrect:', correct)\n",
    "    print('\\tWrong:', wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_guess('test_imgs', 'brick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "predictions = model.predict(np.array([resized_image]))[0]\n",
    "best_guess_index = predictions.index(max(predictions))\n",
    "classifications = {0: 'Brick', 1: 'Siding', 2: 'Unknown'}\n",
    "best_guess_category = classifications[best_guess_index]\n",
    "\n",
    "data['best_guess'] = f'The model has identified {best_guess_category}.'\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    data[classifications[i]] = f'{classifications[i]}: {round(100*prediction,0)}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = plt.imread('test_imgs/brick_62.jpg')\n",
    "img = plt.imshow(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the model's accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['training data', 'validation data'], loc='upper left')\n",
    "plt.savefig('model_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history: \n",
    "plt.plot(history.history['loss'], label='(training data)')\n",
    "plt.plot(history.history['val_loss'], label='(validation data)')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig('model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below Code Needs Significant Modification to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# \"\"\" order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that at training time, our model will never see the exact same picture twice. This helps prevent overfitting and helps the model generalize better.\n",
    "\n",
    "# This can be done by configuring a number of random transformations to be performed on the images read by our ImageDataGenerator instance. Let's get started with an example:\"\"\"\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#       rotation_range=40,\n",
    "#       width_shift_range=0.2,\n",
    "#       height_shift_range=0.2,\n",
    "#       shear_range=0.2,\n",
    "#       zoom_range=0.2,\n",
    "#       horizontal_flip=True,\n",
    "#       fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"These are just a few of the options available (for more, see the Keras documentation. Let's quickly go over what we just wrote:\n",
    "\n",
    "# rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.\n",
    "# width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
    "# shear_range is for randomly applying shearing transformations.\n",
    "# zoom_range is for randomly zooming inside pictures.\n",
    "# horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).\n",
    "# fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "# img_path = os.path.join('resources/data_for_training_06/brick_10\\\\10_13306.jpeg')\n",
    "# img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "# x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "# x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# # The .flow() command below generates batches of randomly transformed images\n",
    "# # It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "# i = 0\n",
    "# for batch in datagen.flow(x, batch_size=1):\n",
    "#   plt.figure(i)\n",
    "#   imgplot = plt.imshow(array_to_img(batch[0]))\n",
    "#   i += 1\n",
    "#   if i % 5 == 0:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_alternative_validation_split_method(main_dir_path, split=0.2):\n",
    "    \n",
    "#     shutil.copytree(main_dir_path, main_dir_path + '_alt')\n",
    "    \n",
    "#     main_dir_path = main_dir_path + '_alt'\n",
    "#     train_path = main_dir_path + '/train'\n",
    "#     validation_path = main_dir_path + '/validate'\n",
    "    \n",
    "#     if os.path.isdir(train_path) or os.path.isdir(validation_path):\n",
    "#         print('You have already split your training and test data')\n",
    "        \n",
    "#     else:\n",
    "#         sub_dir_names = os.listdir(main_dir_path)\n",
    "#         os.mkdir(train_path)\n",
    "#         os.mkdir(validation_path)\n",
    "#         for sub_dir_name in sub_dir_names:\n",
    "#             name = sub_dir_name.split('_')[0]\n",
    "#             os.mkdir(train_path + '/'+ name)\n",
    "#             os.mkdir(validation_path + '/'+ name)\n",
    "#             images = os.listdir(main_dir_path +'/' + sub_dir_name)\n",
    "#             val_n = int(split * len(images))\n",
    "#             val_images = images[:val_n]\n",
    "#             for i in range(len(val_images)):\n",
    "#                 for filepath in glob(main_dir_path +'/' + sub_dir_name + '/' + val_images[i]):\n",
    "#                     shutil.move(main_dir_path +'/' + sub_dir_name + '/' + val_images[i], validation_path +'/' + name + '/' + val_images[i])\n",
    "#             training_images = os.listdir(main_dir_path +'/' + sub_dir_name)\n",
    "#             print(f'{name}: {len(images)} total images')\n",
    "#             print(f'{name}: {len(training_images)} training images')\n",
    "#             print(f'{name}: {val_n} validation images')\n",
    "#             print('validation split: ', 100 * round(val_n/(val_n + len(training_images)),2), '%')\n",
    "#             print()\n",
    "#             for i in range(len(training_images)):\n",
    "#                 for filepath in glob(main_dir_path +'/' + sub_dir_name + '/' + training_images[i]):\n",
    "#                     shutil.move(main_dir_path +'/' + sub_dir_name + '/' + training_images[i], train_path +'/' + name + '/' + training_images[i])\n",
    "#         for sub_dir_name in sub_dir_names:\n",
    "#             os.rmdir(main_dir_path +'/' + sub_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dir = 'resources/data_for_training_06'\n",
    "\n",
    "# my_alternative_validation_split_method(main_dir, split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# # shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,)\n",
    "\n",
    "# # Note that the validation data should not be augmented!\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Flow training images in batches of 32 using train_datagen generator\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         main_dir + '_alt' + '/train',  # This is the source directory for training images\n",
    "#         target_size=(400, 400),  \n",
    "#         batch_size=20,\n",
    "#         # Since we use binary_crossentropy loss, we need binary labels\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# # Flow validation images in batches of 32 using val_datagen generator\n",
    "# validation_generator = val_datagen.flow_from_directory(\n",
    "#         main_dir + '_alt' + '/validate',\n",
    "#         target_size=(400, 400),\n",
    "#         batch_size=20,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters=4, kernel_size=2, padding='same',\n",
    "#                  activation='relu', input_shape=(400, 400, 3)))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv2D(filters=12, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 15\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.image_classifier.hdf5',\n",
    "#                                verbose=1, save_best_only=True)\n",
    "\n",
    "# history = model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),\n",
    "#           epochs=epochs, batch_size=64, callbacks=[checkpointer], verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
